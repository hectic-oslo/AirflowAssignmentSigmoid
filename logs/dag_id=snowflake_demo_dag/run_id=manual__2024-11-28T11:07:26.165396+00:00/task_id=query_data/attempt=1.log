[2024-11-28T11:07:31.306+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: snowflake_demo_dag.query_data manual__2024-11-28T11:07:26.165396+00:00 [queued]>
[2024-11-28T11:07:31.311+0000] {taskinstance.py:1165} INFO - Dependencies all met for <TaskInstance: snowflake_demo_dag.query_data manual__2024-11-28T11:07:26.165396+00:00 [queued]>
[2024-11-28T11:07:31.311+0000] {taskinstance.py:1362} INFO - 
--------------------------------------------------------------------------------
[2024-11-28T11:07:31.311+0000] {taskinstance.py:1363} INFO - Starting attempt 1 of 11
[2024-11-28T11:07:31.311+0000] {taskinstance.py:1364} INFO - 
--------------------------------------------------------------------------------
[2024-11-28T11:07:31.318+0000] {taskinstance.py:1383} INFO - Executing <Task(SnowflakeOperator): query_data> on 2024-11-28 11:07:26.165396+00:00
[2024-11-28T11:07:31.320+0000] {standard_task_runner.py:55} INFO - Started process 525 to run task
[2024-11-28T11:07:31.322+0000] {standard_task_runner.py:82} INFO - Running: ['***', 'tasks', 'run', 'snowflake_demo_dag', 'query_data', 'manual__2024-11-28T11:07:26.165396+00:00', '--job-id', '8', '--raw', '--subdir', 'DAGS_FOLDER/snowflake_dag.py', '--cfg-path', '/tmp/tmp8nfwgpli']
[2024-11-28T11:07:31.322+0000] {standard_task_runner.py:83} INFO - Job 8: Subtask query_data
[2024-11-28T11:07:31.352+0000] {task_command.py:376} INFO - Running <TaskInstance: snowflake_demo_dag.query_data manual__2024-11-28T11:07:26.165396+00:00 [running]> on host e85eb02d191d
[2024-11-28T11:07:31.383+0000] {taskinstance.py:1592} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=snowflake_demo_dag
AIRFLOW_CTX_TASK_ID=query_data
AIRFLOW_CTX_EXECUTION_DATE=2024-11-28T11:07:26.165396+00:00
AIRFLOW_CTX_TRY_NUMBER=1
AIRFLOW_CTX_DAG_RUN_ID=manual__2024-11-28T11:07:26.165396+00:00
[2024-11-28T11:07:31.383+0000] {sql.py:265} INFO - Executing: 
SELECT * FROM demo_table;
[2024-11-28T11:07:31.387+0000] {base.py:71} INFO - Using connection ID 'snowflake_conn_id' for task execution.
[2024-11-28T11:07:31.662+0000] {warnings.py:110} WARNING - /home/***/.local/lib/python3.7/site-packages/snowflake/connector/options.py:109: UserWarning: You have an incompatible version of 'pyarrow' installed (6.0.1), please install a version that adheres to: 'pyarrow<10.1.0,>=10.0.1; extra == "pandas"'
  "pyarrow", installed_pyarrow_version, pandas_pyarrow_extra

[2024-11-28T11:07:31.789+0000] {base.py:71} INFO - Using connection ID 'snowflake_conn_id' for task execution.
[2024-11-28T11:07:31.789+0000] {connection.py:300} INFO - Snowflake Connector for Python Version: 3.0.4, Python Version: 3.7.15, Platform: Linux-6.10.4-linuxkit-aarch64-with-debian-11.5
[2024-11-28T11:07:31.790+0000] {connection.py:1013} INFO - This connection is in OCSP Fail Open Mode. TLS Certificates would be checked for validity and revocation status. Any other Certificate Revocation related exceptions or OCSP Responder failures would be disregarded in favor of connectivity.
[2024-11-28T11:07:31.790+0000] {connection.py:1023} INFO - THIS CONNECTION IS IN INSECURE MODE. IT MEANS THE CERTIFICATE WILL BE VALIDATED BUT THE CERTIFICATE REVOCATION STATUS WILL NOT BE CHECKED.
[2024-11-28T11:07:31.790+0000] {connection.py:1030} INFO - Setting use_openssl_only mode to False
[2024-11-28T11:07:32.038+0000] {ssl_wrap_socket.py:101} INFO - THIS CONNECTION IS IN INSECURE MODE. IT MEANS THE CERTIFICATE WILL BE VALIDATED BUT THE CERTIFICATE REVOCATION STATUS WILL NOT BE CHECKED.
[2024-11-28T11:07:32.205+0000] {cursor.py:806} INFO - query: [ALTER SESSION SET autocommit=False]
[2024-11-28T11:07:32.349+0000] {cursor.py:819} INFO - query execution done
[2024-11-28T11:07:32.351+0000] {cursor.py:962} INFO - Number of results in first chunk: 1
[2024-11-28T11:07:32.353+0000] {sql.py:375} INFO - Running statement: SELECT * FROM demo_table;, parameters: None
[2024-11-28T11:07:32.354+0000] {cursor.py:806} INFO - query: [SELECT * FROM demo_table;]
[2024-11-28T11:07:32.525+0000] {cursor.py:819} INFO - query execution done
[2024-11-28T11:07:32.525+0000] {cursor.py:962} INFO - Number of results in first chunk: 2
[2024-11-28T11:07:32.526+0000] {sql.py:384} INFO - Rows affected: 2
[2024-11-28T11:07:32.527+0000] {snowflake.py:391} INFO - Rows affected: 2
[2024-11-28T11:07:32.527+0000] {snowflake.py:392} INFO - Snowflake query id: 01b8abfb-0001-3903-0006-ac5e0001a8c2
[2024-11-28T11:07:32.528+0000] {cursor.py:806} INFO - query: [COMMIT]
[2024-11-28T11:07:32.630+0000] {cursor.py:819} INFO - query execution done
[2024-11-28T11:07:32.630+0000] {cursor.py:962} INFO - Number of results in first chunk: 1
[2024-11-28T11:07:32.631+0000] {connection.py:605} INFO - closed
[2024-11-28T11:07:32.696+0000] {connection.py:608} INFO - No async queries seem to be running, deleting session
[2024-11-28T11:07:32.778+0000] {xcom.py:600} ERROR - Could not serialize the XCom value into JSON. If you are using pickle instead of JSON for XCom, then you need to enable pickle support for XCom in your *** config.
[2024-11-28T11:07:32.779+0000] {taskinstance.py:1851} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/taskinstance.py", line 2385, in xcom_push
    session=session,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/utils/session.py", line 72, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 212, in set
    map_index=map_index,
  File "/home/airflow/.local/lib/python3.7/site-packages/airflow/models/xcom.py", line 597, in serialize_value
    return json.dumps(value).encode('UTF-8')
  File "/usr/local/lib/python3.7/json/__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "/usr/local/lib/python3.7/json/encoder.py", line 199, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/local/lib/python3.7/json/encoder.py", line 257, in iterencode
    return _iterencode(o, 0)
  File "/usr/local/lib/python3.7/json/encoder.py", line 179, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type datetime is not JSON serializable
[2024-11-28T11:07:32.789+0000] {taskinstance.py:1406} INFO - Marking task as UP_FOR_RETRY. dag_id=snowflake_demo_dag, task_id=query_data, execution_date=20241128T110726, start_date=20241128T110731, end_date=20241128T110732
[2024-11-28T11:07:32.802+0000] {standard_task_runner.py:105} ERROR - Failed to execute job 8 for task query_data (Object of type datetime is not JSON serializable; 525)
[2024-11-28T11:07:32.819+0000] {local_task_job.py:164} INFO - Task exited with return code 1
[2024-11-28T11:07:32.832+0000] {local_task_job.py:273} INFO - 0 downstream tasks scheduled from follow-on schedule check
